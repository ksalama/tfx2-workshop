{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive ML with TensorFlow Extended (TFX) Pipelines\n",
    "1. Extracting the new training data from the source using [ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen) component.\n",
    "2. Validating new training data\n",
    "    * Generating statistics from the the incoming data using [StatisticsGen](https://www.tensorflow.org/tfx/guide/statsgen) component.\n",
    "    * Importing a fixed raw schema using [ImporterNode](https://github.com/tensorflow/tfx/blob/master/tfx/components/common_nodes/importer_node.py) component.\n",
    "    * Validating data based on the schema using [ExampleValidator](https://www.tensorflow.org/tfx/guide/exampleval) component.\n",
    "5. Transforming the data for ML using the [Transform](https://www.tensorflow.org/tfx/guide/transform) component.\n",
    "6. Training the model using the [Trainer](https://www.tensorflow.org/tfx/guide/trainer) component.\n",
    "7. Evaluate the model using the [Evaluator](https://www.tensorflow.org/tfx/guide/evaluator) component.\n",
    "8. Validate the model using a [Custom TFX](https://www.tensorflow.org/tfx/guide/custom_component) component.\n",
    "9. Push the the blessed model to serving locationusing [Pusher](https://www.tensorflow.org/tfx/guide/pusher) component.\n",
    "10. Query the [ML Metadata](https://www.tensorflow.org/tfx/guide/mlmd) DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tfx\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_model_analysis as tfma\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "logger = tf.get_logger()\n",
    "\n",
    "print(\"Tensorflow Version:\", tf.__version__)\n",
    "print(\"TFX Version:\", tfx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = 'workspace'\n",
    "DATA_DIR = WORKSPACE + '/data'\n",
    "RAW_SCHEMA_DIR =  'ml_pipeline/raw_schema'\n",
    "OUTPUT_DIR = WORKSPACE + '/artifacts'\n",
    "MODEL_REGISTRY = WORKSPACE + '/model_registry'\n",
    "\n",
    "REMOVE_ARTIFACTS = True\n",
    "if REMOVE_ARTIFACTS:\n",
    "    if tf.io.gfile.exists(OUTPUT_DIR):\n",
    "        print(\"Removing previous artifacts...\")\n",
    "        tf.io.gfile.rmtree(OUTPUT_DIR)\n",
    "    if tf.io.gfile.exists(MODEL_REGISTRY):\n",
    "        print(\"Removing previous model regitry...\")\n",
    "        tf.io.gfile.rmtree(MODEL_REGISTRY)\n",
    "        \n",
    "tf.io.gfile.mkdir(MODEL_REGISTRY)\n",
    "print(\"Model registry directory created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Interactive Context\n",
    "This will use an ephemeral SQLite MLMD connection contained in the pipeline_root directory with file name \"metadata.sqlite\" will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "PIPELINE_NAME = 'tfx-census-classification'\n",
    "\n",
    "context = InteractiveContext(\n",
    "    pipeline_name=PIPELINE_NAME,\n",
    "    pipeline_root=OUTPUT_DIR,\n",
    "    metadata_connection_config=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(\"Standard Artifact types:\")\n",
    "pprint([a for a in dir(tfx.types.standard_artifacts) if a[0].isupper()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion (ExampleGen)\n",
    "1. Reads the CSV data files (expecting to include headers)\n",
    "2. Split the data to train and eval sets\n",
    "3. Write the data to TFRecords\n",
    "\n",
    "\n",
    "* **Inputs**: ExternalPath\n",
    "* **Ouptpus**: Examples (TFRecords)\n",
    "* **Properties**: split ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.utils.dsl_utils import external_input\n",
    "from tfx.proto import example_gen_pb2\n",
    "\n",
    "output_config = example_gen_pb2.Output(\n",
    "    split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "        example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=3),\n",
    "        example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "    ]))\n",
    "\n",
    "\n",
    "example_gen = tfx.components.CsvExampleGen(\n",
    "    instance_name='Data_Extraction_Spliting',\n",
    "    input=external_input(DATA_DIR),\n",
    "    output_config=output_config\n",
    ")\n",
    "\n",
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_data_validation as tfdv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample of the extracted data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uri = example_gen.outputs.examples.get()[0].uri + \"/train/*\"\n",
    "\n",
    "tfrecord_filenames = tf.data.Dataset.list_files(train_uri)\n",
    "\n",
    "# Create a `TFRecordDataset` to read these files\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "\n",
    "# Display some records\n",
    "for tfrecord in dataset.shuffle(1000).take(1):\n",
    "    serialized_example = tfrecord.numpy()\n",
    "    print(tf.train.Example.FromString(serialized_example).features)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Validation\n",
    "1. Generate the **statistics** for the data to validate.\n",
    "2. Import the **raw_schema** created in the Data Analysis phase.\n",
    "3. Validat the **statistics** against the schema and generate **anomalies** (if any)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Generating statistics for the data to validate (StatisticsGen)\n",
    "* **Inputs**: Examples\n",
    "* **Outputs**: ExampleStatistics\n",
    "* **Properries**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_gen = tfx.components.StatisticsGen(\n",
    "    instance_name='Statistics_Generation',\n",
    "    examples=example_gen.outputs.examples)\n",
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Import the fixed raw schema (ImporterNode)\n",
    "The **ImporterNode** allows you to import an external artifact to a component.\n",
    "You need to specifiy:\n",
    "1. Artifact Type\n",
    "2. Artifcat Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_importer = tfx.components.common_nodes.importer_node.ImporterNode(\n",
    "    instance_name='Schema_Importer',\n",
    "    source_uri=RAW_SCHEMA_DIR,\n",
    "    artifact_type=tfx.types.standard_artifacts.Schema,\n",
    "    reimport=False\n",
    ")\n",
    "\n",
    "context.run(schema_importer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(schema_importer.outputs.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Validate the input data statistics (ExampleValidator)\n",
    "* **Inputs**: ExampleStatistics, Schema\n",
    "* **Outputs**: ExampleAnomalies (if any)\n",
    "* **Properties**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator = tfx.components.ExampleValidator(\n",
    "    statistics=statistics_gen.outputs.statistics,\n",
    "    schema=schema_importer.outputs.result,\n",
    "    instance_name=\"Data_Validation\"\n",
    ")\n",
    "\n",
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(example_validator.outputs.anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Implement the preprocessing logic\n",
    "\n",
    "We need to implement the preprocessing logic in a python module: **transform.py**.\n",
    "\n",
    "* This module is expected to have **preprocessing_fn** method, which accepts a dictionary of the raw features, and returns a dictionary of the transformed features.\n",
    "* We use the **raw schema** to identify feature types and the required transformation.\n",
    "* The function is implemented using [TensorFlow Transform](https://www.tensorflow.org/tfx/guide/tft)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Tranform train and eval data (Transform)\n",
    "\n",
    "The component uses the transform output generated from transforming the train data to transform eval data.\n",
    "That is, while the train data is **analyzed** and **transformed**, the eval data is **only transformed** uaing the output of the analyze phase (TransformGraph) on the train data.\n",
    "\n",
    "* **Inputs**: train and eval data (Examples), raw schema (Schema), transformation module (file)\n",
    "* **outputs**: transformed train and eval data (Examples), transform output (TransformGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "_transform_module_file = 'ml_pipeline/modules/transform.py'\n",
    "\n",
    "transform = tfx.components.Transform(\n",
    "    examples=example_gen.outputs.examples,\n",
    "    schema=schema_importer.outputs.result,\n",
    "    module_file=_transform_module_file,\n",
    "    instance_name=\"Data_Transformation\"\n",
    ")\n",
    "\n",
    "context.run(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = transform.outputs.transform_graph.get()[0].uri\n",
    "os.listdir(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model (Trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Implement a train Python module.\n",
    "\n",
    "Create a Python module containing the following methods.\n",
    "\n",
    "1. create_dataset: loads data for training and evaluation\n",
    "2. create_feature_columns: defines the model interface\n",
    "3. create_keras_model: defines model architecture and optimization algorithm\n",
    "4. create_serving_signature: defines the exported model interface\n",
    "\n",
    "The entry point of the module is the **run_fn**, which trains, evaluates, and exports the model.\n",
    "The function takes **params** as argument, which includes the required parameters for creating and traniing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_pipeline.modules import train\n",
    "transform_output = tft.TFTransformOutput(transform.outputs.transform_graph.get()[0].uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train_uri = transform.outputs.transformed_examples.get()[0].uri + \"/train/*\"\n",
    "\n",
    "sample_dataset = train.create_dataset(\n",
    "    transformed_train_uri, transform_output, batch_size=5, shuffle=True)\n",
    "\n",
    "for input_features, target in sample_dataset.take(2):\n",
    "    print(\"Features:\")\n",
    "    for key, values in input_features.items():\n",
    "        print(\"- {}: {}\".format(key, values.numpy().tolist()))\n",
    "    print(\"Targets:\", list(target.numpy().tolist()))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = train.create_feature_columns(transform_output)\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train.create_keras_model(None, feature_columns)\n",
    "model(input_features)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - model signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_signatures = train.create_model_signatures(model, transform_output)\n",
    "serving_fn = model_signatures['serving_features']\n",
    "\n",
    "print(\"Serving fn inputs:\")\n",
    "print(\"------------------\")\n",
    "pprint(serving_fn.structured_input_signature[0])\n",
    "\n",
    "print(\"Serving fn outputs:\")\n",
    "print(\"-------------------\")\n",
    "pprint(serving_fn.structured_outputs)\n",
    "print(\"\")\n",
    "\n",
    "eval_fn = model_signatures['serving_default']\n",
    "print(\"Eval fn inputs:\")\n",
    "print(\"---------------\")\n",
    "pprint(eval_fn.structured_input_signature[0])\n",
    "\n",
    "print(\"Eval fn outputs:\")\n",
    "print(\"----------------\")\n",
    "pprint(eval_fn.structured_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train the model using the Trainer component\n",
    "* **Inputs**: train module file with the **trainer_fn**, raw schema (Schema), and transform output (TransformGraph)\n",
    "* **Outputs**: saved_model (Model)\n",
    "* **Properties**: train and eval args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tfx.components.base import executor_spec\n",
    "from tfx.components.trainer import executor as trainer_executor\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "_train_module_file = 'ml_pipeline/modules/train.py'\n",
    "\n",
    "trainer = tfx.components.Trainer(\n",
    "    custom_executor_spec=executor_spec.ExecutorClassSpec(trainer_executor.GenericExecutor),\n",
    "    module_file=_train_module_file,\n",
    "    transformed_examples=transform.outputs.transformed_examples,\n",
    "    schema=schema_importer.outputs.result,\n",
    "    transform_graph=transform.outputs.transform_graph,\n",
    "    train_args=tfx.proto.trainer_pb2.TrainArgs(num_steps=1000),\n",
    "    eval_args=tfx.proto.trainer_pb2.EvalArgs(num_steps=None),\n",
    "    instance_name='Census_Classifier_Trainer'\n",
    ")\n",
    "\n",
    "context.run(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uri = trainer.outputs.model.get()[0].uri\n",
    "saved_model_dir = os.path.join(train_uri, 'serving_model_dir')\n",
    "print(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {saved_model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the trained model (Evaluator)\n",
    "* **Inputs**: eval data (Examples), trained model (Model)\n",
    "* **Outputs** eval metric (ModelEvaluation)\n",
    "* **Properties**: Slicing Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_pipeline.modules import helper\n",
    "eval_config = helper.get_eval_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analyzer = tfx.components.Evaluator(\n",
    "    instance_name=\"Occupation_based_Evaluator\",\n",
    "    examples=example_gen.outputs.examples,\n",
    "    model=trainer.outputs.model,\n",
    "    eval_config=eval_config\n",
    ")\n",
    "\n",
    "context.run(model_analyzer, enable_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "results_uri = model_analyzer.outputs.output.get()[0].uri\n",
    "results = tfma.load_eval_result(results_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total evaluation examples:', int(results.slicing_metrics[0][1]['']['']['example_count']['doubleValue']))\n",
    "print('Overal evaluation accuracy:', round(results.slicing_metrics[0][1]['']['']['binary_accuracy']['doubleValue']*100, 2), '%')\n",
    "print(\"\")\n",
    "for slicing_metric in results.slicing_metrics[1:]:\n",
    "    label = \"{}:{}\".format(slicing_metric[0][0][0], slicing_metric[0][0][1])\n",
    "    example_count = int(slicing_metric[1]['']['']['example_count']['doubleValue'])\n",
    "    accuray = round(slicing_metric[1]['']['']['binary_accuracy']['doubleValue']*100, 2)\n",
    "    print('{} - example count: {}, accuracy: {}'.format(label, example_count, accuray), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validate the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a Custom TFX Component that validates the trained model based on its produced evaluation metric.\n",
    "\n",
    "The custom validator will **bless** the model if:\n",
    "1. Overal accuracy is greater than 85%.\n",
    "2. Accuracy per **Occupation** slice is at most 10% less than the overall accuracy.\n",
    "\n",
    "* **Inputs**: Evaluation Metric (ModelEvaluation), trained model (Model)\n",
    "* **Outputs**: blessing (ModelBlessing)\n",
    "* **Properties**: accuracy_threshold, slice_accuracy_tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_pipeline.modules import custom_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_model_validator = custom_components.AccuracyModelValidator(\n",
    "    eval_results=model_analyzer.outputs.output,\n",
    "    model=trainer.outputs.model,\n",
    "    accuracy_threshold=0.5,\n",
    "    slice_accuracy_tolerance=0.15,\n",
    "    instance_name=\"Accuracy_Model_Validator\"\n",
    ")\n",
    "\n",
    "context.run(accuracy_model_validator, enable_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blessing_uri = accuracy_model_validator.outputs.blessing.get()[0].uri\n",
    "!ls -l {blessing_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pushing the Blessed Model (Pusher)\n",
    "This steps pushes the validated and blessed model to its final destination. This could be:\n",
    "1. Model Registry\n",
    "2. Git Repository\n",
    "3. API Serving Platform\n",
    "4. Filesystem location\n",
    "5. Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Push the blessed model to model registry (filesystem location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_model_location = os.path.join(MODEL_REGISTRY, 'census')\n",
    "\n",
    "push_destination=tfx.proto.pusher_pb2.PushDestination(\n",
    "    filesystem=tfx.proto.pusher_pb2.PushDestination.Filesystem(\n",
    "        base_directory=exported_model_location)\n",
    ")\n",
    "\n",
    "pusher = tfx.components.Pusher(\n",
    "    model=trainer.outputs.model,\n",
    "    model_blessing=accuracy_model_validator.outputs.blessing,\n",
    "    push_destination=push_destination\n",
    ")\n",
    "\n",
    "context.run(pusher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Test the pushed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_serving_model_path = os.path.join(exported_model_location, max(os.listdir(exported_model_location)))\n",
    "print(latest_serving_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {latest_serving_model_path} --tag_set serve --signature_def serving_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "predictor = tf.saved_model.load(\n",
    "    latest_serving_model_path).signatures[\"serving_features\"]\n",
    "\n",
    "def create_tf_features(instance):\n",
    "    new_instance = {}\n",
    "    for key, value in instance.items():\n",
    "        new_instance[key] = tf.constant(\n",
    "            value, \n",
    "            dtype=serving_fn.structured_input_signature[0][0][key].dtype\n",
    "        )\n",
    "    return new_instance\n",
    "\n",
    "def local_predict(instance):\n",
    "    features = create_tf_features(instance)\n",
    "    outputs = predictor(**features)\n",
    "    return outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = {\n",
    "    'age': [34],\n",
    "    'workclass': ['Private'],\n",
    "    'education': ['Doctorate'],\n",
    "    'education_num': [10],\n",
    "    'marital_status': ['Married-civ-spouse'],\n",
    "    'occupation': ['Prof-specialty'],\n",
    "    'relationship': ['Husband'],\n",
    "    'race': ['White'],\n",
    "    'gender': ['Male'],\n",
    "    'capital_gain': [0], \n",
    "    'capital_loss': [0], \n",
    "    'hours_per_week': [40],\n",
    "    'native_country':['Egyptian']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = local_predict(instance)\n",
    "\n",
    "predictions = list(\n",
    "    zip(outputs[LABEL_KEY].numpy().tolist(), \n",
    "        outputs[SCORE_KEY].numpy().tolist()))\n",
    "\n",
    "for prediction in predictions:\n",
    "    print(\"Predicted label: {} - Prediction confidence: {}\".format(\n",
    "        prediction[0], round(prediction[1], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Querying Metadata database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "connection = sqlite3.connect(os.path.join(OUTPUT_DIR, 'metadata.sqlite'))\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "pprint(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Artifact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM Artifact;\")\n",
    "for entry in cursor.fetchall():\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
