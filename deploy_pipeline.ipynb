{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Deploy the TFX Pipeline to KFP\n",
    "\n",
    "This Notebook helps you to compile the **TFX Pipeline** to a **KFP package**. This will creat an **Argo YAML** file in a **.tar.gz** package. We perform the following steps:\n",
    "1. Build a custom container image that include our modules\n",
    "2. Compile TFX Pipeline using CLI\n",
    "3. Deploy the compiled pipeline to KFP \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set compile time variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PROJECT_ID\"]=\"ksalama-research\" # Set your project\n",
    "\n",
    "os.environ[\"IMAGE_NAME\"]=\"tfx-image\"\n",
    "os.environ[\"TAG\"]=\"latest\"\n",
    "os.environ[\"KFP_TFX_IMAGE\"]=\"gcr.io/{}/{}:{}\".format(\n",
    "    os.environ.get(\"PROJECT_ID\"), \n",
    "    os.environ.get(\"IMAGE_NAME\"),\n",
    "    os.environ.get(\"TAG\"))\n",
    "\n",
    "os.environ[\"NAMESPACE\"]=\"kubeflow-pipelines\"\n",
    "os.environ[\"GCP_REGION\"]=\"europe-west1\" # Set your region\n",
    "os.environ[\"ARTIFACT_STORE_URI\"]=\"gs://ks-kfp-artifact-store\" # Set your GCS Bucket\n",
    "os.environ[\"GCS_STAGING_PATH\"]=os.environ.get(\"ARTIFACT_STORE_URI\")+\"/staging\"\n",
    "os.environ[\"GKE_CLUSTER_NAME\"]=\"ks-ml-cluster-01\" # Set your GKE cluster name\n",
    "os.environ[\"GKE_CLUSTER_ZONE\"]=\"europe-west1-b\" # Set your GKE cluster zone\n",
    "os.environ[\"RUNTIME_VERSION\"]=\"1.15\"\n",
    "os.environ[\"PYTHON_VERSION\"]=\"3.7\"\n",
    "os.environ[\"BEAM_RUNNER\"]=\"DirectRunner\"\n",
    "\n",
    "os.environ[\"PIPELINE_NAME\"]=\"tfx_census_classification\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Container Image\n",
    "\n",
    "The pipeline uses a custom docker image, which is a derivative of the [tensorflow/tfx:0.21.4](https://hub.docker.com/r/tensorflow/tfx) image, as a runtime execution environment for the pipeline's components. The same image is also used as a a training image used by **AI Platform Training**.\n",
    "\n",
    "The custom image modifies the base image by adding the `modules` and `raw_schema` folders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 24 file(s) totalling 68.7 KiB before compression.\n",
      "Uploading tarball of [./ml_pipeline] to [gs://ksalama-research_cloudbuild/source/1595281626.93-4dcf1e8f65fd4b7dbebee66136277849.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/ksalama-research/builds/6782e309-ca5c-4e97-b1e9-8e2e050f21f8].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/6782e309-ca5c-4e97-b1e9-8e2e050f21f8?project=944117458110].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"6782e309-ca5c-4e97-b1e9-8e2e050f21f8\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://ksalama-research_cloudbuild/source/1595281626.93-4dcf1e8f65fd4b7dbebee66136277849.tgz#1595281627596680\n",
      "Copying gs://ksalama-research_cloudbuild/source/1595281626.93-4dcf1e8f65fd4b7dbebee66136277849.tgz#1595281627596680...\n",
      "/ [1 files][ 16.1 KiB/ 16.1 KiB]                                                \n",
      "Operation completed over 1 objects/16.1 KiB.                                     \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "\n",
      "                   ***** NOTICE *****\n",
      "\n",
      "Alternative official `docker` images, including multiple versions across\n",
      "multiple platforms, are maintained by the Docker Team. For details, please\n",
      "visit https://hub.docker.com/_/docker.\n",
      "\n",
      "                ***** END OF NOTICE *****\n",
      "\n",
      "Sending build context to Docker daemon  91.14kB\n",
      "Step 1/2 : FROM tensorflow/tfx:0.21.4\n",
      "0.21.4: Pulling from tensorflow/tfx\n",
      "bd47987755ba: Pulling fs layer\n",
      "831c222b21d8: Pulling fs layer\n",
      "3c2cba919283: Pulling fs layer\n",
      "e378d88a5f59: Pulling fs layer\n",
      "df37508d2f5c: Pulling fs layer\n",
      "bd5056198be8: Pulling fs layer\n",
      "044a6cc327bc: Pulling fs layer\n",
      "c7411e31635f: Pulling fs layer\n",
      "29aa6e9dcc22: Pulling fs layer\n",
      "9777e791df93: Pulling fs layer\n",
      "9adf91901ea3: Pulling fs layer\n",
      "1bb0820f7158: Pulling fs layer\n",
      "8aa238cf5652: Pulling fs layer\n",
      "b57d894b9e7f: Pulling fs layer\n",
      "e378d88a5f59: Waiting\n",
      "df37508d2f5c: Waiting\n",
      "bd5056198be8: Waiting\n",
      "044a6cc327bc: Waiting\n",
      "29aa6e9dcc22: Waiting\n",
      "9777e791df93: Waiting\n",
      "9adf91901ea3: Waiting\n",
      "1bb0820f7158: Waiting\n",
      "8aa238cf5652: Waiting\n",
      "b57d894b9e7f: Waiting\n",
      "c7411e31635f: Waiting\n",
      "3c2cba919283: Verifying Checksum\n",
      "3c2cba919283: Download complete\n",
      "831c222b21d8: Verifying Checksum\n",
      "831c222b21d8: Download complete\n",
      "bd47987755ba: Verifying Checksum\n",
      "bd47987755ba: Download complete\n",
      "bd5056198be8: Verifying Checksum\n",
      "bd5056198be8: Download complete\n",
      "044a6cc327bc: Verifying Checksum\n",
      "044a6cc327bc: Download complete\n",
      "c7411e31635f: Verifying Checksum\n",
      "c7411e31635f: Download complete\n",
      "e378d88a5f59: Verifying Checksum\n",
      "e378d88a5f59: Download complete\n",
      "df37508d2f5c: Verifying Checksum\n",
      "df37508d2f5c: Download complete\n",
      "bd47987755ba: Pull complete\n",
      "9adf91901ea3: Verifying Checksum\n",
      "9adf91901ea3: Download complete\n",
      "9777e791df93: Verifying Checksum\n",
      "9777e791df93: Download complete\n",
      "8aa238cf5652: Verifying Checksum\n",
      "8aa238cf5652: Download complete\n",
      "b57d894b9e7f: Verifying Checksum\n",
      "b57d894b9e7f: Download complete\n",
      "831c222b21d8: Pull complete\n",
      "1bb0820f7158: Verifying Checksum\n",
      "1bb0820f7158: Download complete\n",
      "3c2cba919283: Pull complete\n",
      "29aa6e9dcc22: Verifying Checksum\n",
      "29aa6e9dcc22: Download complete\n",
      "e378d88a5f59: Pull complete\n",
      "df37508d2f5c: Pull complete\n",
      "bd5056198be8: Pull complete\n",
      "044a6cc327bc: Pull complete\n",
      "c7411e31635f: Pull complete\n",
      "29aa6e9dcc22: Pull complete\n",
      "9777e791df93: Pull complete\n",
      "9adf91901ea3: Pull complete\n",
      "1bb0820f7158: Pull complete\n",
      "8aa238cf5652: Pull complete\n",
      "b57d894b9e7f: Pull complete\n",
      "Digest: sha256:f5c313fb9dd86c3eaade35265e93d6037cc56f438924a13d32e6633e6cb3cbac\n",
      "Status: Downloaded newer image for tensorflow/tfx:0.21.4\n",
      " ---> 8acabd98b4f0\n",
      "Step 2/2 : ADD ml_pipeline ml_pipeline\n",
      "ADD failed: stat /var/lib/docker/tmp/docker-builder001331875/ml_pipeline: no such file or directory\n",
      "ERROR\n",
      "ERROR: build step 0 \"gcr.io/cloud-builders/docker\" failed: step exited with non-zero status: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.builds.submit) build 6782e309-ca5c-4e97-b1e9-8e2e050f21f8 completed with status \"FAILURE\"\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag $KFP_TFX_IMAGE ./ml_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compile TFX Pipeline using CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tfx pipeline --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-20 21:52:59.561435: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-07-20 21:52:59.561592: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-07-20 21:52:59.561624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "CLI\n",
      "Compiling pipeline\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "2020-07-20 21:53:03.331527: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-07-20 21:53:03.331680: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-07-20 21:53:03.331703: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/lib/python3.7/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
      "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n",
      "WARNING:absl:The \"input_data\" argument to the StatisticsGen component has been renamed to \"examples\" and is deprecated. Please update your usage as support for this argument will be removed soon.\n",
      "WARNING:absl:The \"stats\" argument to the StatisticsGen component has been renamed to \"statistics\" and is deprecated. Please update your usage as support for this argument will be removed soon.\n",
      "WARNING:absl:The \"input_data\" argument to the Transform component has been renamed to \"examples\" and is deprecated. Please update your usage as support for this argument will be removed soon.\n",
      "WARNING:absl:The \"model_export\" argument to the Pusher component has been renamed to \"model\" and is deprecated. Please update your usage as support for this argument will be removed soon.\n",
      "Pipeline compiled successfully.\n",
      "Pipeline package path: /home/tfx2-workshop/tfx_census_classification.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!tfx pipeline compile \\\n",
    "    --engine=kubeflow \\\n",
    "    --pipeline_path=ml_pipeline/runner.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy the Compiled Pipeline to KFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kfp pipeline --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Details\n",
      "------------------\n",
      "ID           a6d1db77-d91a-440f-ae71-0557cc4624da\n",
      "Name         tfx_census_classification\n",
      "Description\n",
      "Uploaded at  2020-07-20T21:54:30+00:00\n",
      "+--------------------+-----------------------------------------------------------------------+\n",
      "| Parameter Name     | Default Value                                                         |\n",
      "+====================+=======================================================================+\n",
      "| pipeline-root      | gs://ks-kfp-artifact-store/tfx_census_classification/{{workflow.uid}} |\n",
      "+--------------------+-----------------------------------------------------------------------+\n",
      "| eval-steps         | 500                                                                   |\n",
      "+--------------------+-----------------------------------------------------------------------+\n",
      "| train-steps        | 5000                                                                  |\n",
      "+--------------------+-----------------------------------------------------------------------+\n",
      "| accuracy-threshold | 0.75                                                                  |\n",
      "+--------------------+-----------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching cluster endpoint and auth data.\n",
      "kubeconfig entry generated for ks-ml-cluster-01.\n",
      "Pipeline a6d1db77-d91a-440f-ae71-0557cc4624da has been submitted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gcloud container clusters get-credentials ${GKE_CLUSTER_NAME} --zone ${GKE_CLUSTER_ZONE}\n",
    "export INVERSE_PROXY_HOSTNAME=$(kubectl describe configmap inverse-proxy-config -n ${NAMESPACE} | grep \"googleusercontent.com\")\n",
    "\n",
    "kfp --namespace=${NAMESPACE} --endpoint=${INVERSE_PROXY_HOSTNAME} \\\n",
    "    pipeline upload \\\n",
    "    --pipeline-name=${PIPELINE_NAME} \\\n",
    "    ${PIPELINE_NAME}.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the KFP UI to run the deployed pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
