{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Deploy the TFX Pipeline to KFP\n",
    "\n",
    "This Notebook helps you to compile the **TFX Pipeline** to a **KFP package**. This will creat an **Argo YAML** file in a **.tar.gz** package. We perform the following steps:\n",
    "1. Build a custom container image that include our modules\n",
    "2. Compile TFX Pipeline using CLI\n",
    "3. Deploy the compiled pipeline to KFP \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set compile time variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PROJECT_ID\"]=\"ksalama-research\" # Set your project\n",
    "\n",
    "os.environ[\"IMAGE_NAME\"]=\"tfx-image\"\n",
    "os.environ[\"TAG\"]=\"latest\"\n",
    "os.environ[\"KFP_TFX_IMAGE\"]=\"gcr.io/{}/{}:{}\".format(\n",
    "    os.environ.get(\"PROJECT_ID\"), \n",
    "    os.environ.get(\"IMAGE_NAME\"),\n",
    "    os.environ.get(\"TAG\"))\n",
    "\n",
    "os.environ[\"NAMESPACE\"]=\"kubeflow-pipelines\"\n",
    "os.environ[\"GCP_REGION\"]=\"europe-west1\" # Set your region\n",
    "os.environ[\"ARTIFACT_STORE_URI\"]=\"gs://ks-kfp-artifact-store\" # Set your GCS Bucket\n",
    "os.environ[\"GCS_STAGING_PATH\"]=os.environ.get(\"ARTIFACT_STORE_URI\")+\"/staging\"\n",
    "os.environ[\"GKE_CLUSTER_NAME\"]=\"ks-ml-cluster-01\" # Set your GKE cluster name\n",
    "os.environ[\"GKE_CLUSTER_ZONE\"]=\"europe-west1-b\" # Set your GKE cluster zone\n",
    "os.environ[\"RUNTIME_VERSION\"]=\"1.15\"\n",
    "os.environ[\"PYTHON_VERSION\"]=\"3.7\"\n",
    "os.environ[\"BEAM_RUNNER\"]=\"DirectRunner\"\n",
    "\n",
    "os.environ[\"PIPELINE_NAME\"]=\"tfx_census_classification\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Container Image\n",
    "\n",
    "The pipeline uses a custom docker image, which is a derivative of the [tensorflow/tfx:0.21.4](https://hub.docker.com/r/tensorflow/tfx) image, as a runtime execution environment for the pipeline's components. The same image is also used as a a training image used by **AI Platform Training**.\n",
    "\n",
    "The custom image modifies the base image by adding the `modules` and `raw_schema` folders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 25 file(s) totalling 337.2 KiB before compression.\n",
      "Some files were not included in the source upload.\n",
      "\n",
      "Check the gcloud log [/root/.config/gcloud/logs/2020.07.20/23.35.19.809871.log] to see which files and the contents of the\n",
      "default gcloudignore file used (see `$ gcloud topic gcloudignore` to learn\n",
      "more).\n",
      "\n",
      "Uploading tarball of [.] to [gs://ksalama-research_cloudbuild/source/1595288119.93-9292d51ed26e482094c3c14159b00b63.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/ksalama-research/builds/09eafa18-7649-4531-a00d-c2714802a623].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/09eafa18-7649-4531-a00d-c2714802a623?project=944117458110].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"09eafa18-7649-4531-a00d-c2714802a623\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://ksalama-research_cloudbuild/source/1595288119.93-9292d51ed26e482094c3c14159b00b63.tgz#1595288120688051\n",
      "Copying gs://ksalama-research_cloudbuild/source/1595288119.93-9292d51ed26e482094c3c14159b00b63.tgz#1595288120688051...\n",
      "/ [1 files][ 40.2 KiB/ 40.2 KiB]                                                \n",
      "Operation completed over 1 objects/40.2 KiB.                                     \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "\n",
      "                   ***** NOTICE *****\n",
      "\n",
      "Alternative official `docker` images, including multiple versions across\n",
      "multiple platforms, are maintained by the Docker Team. For details, please\n",
      "visit https://hub.docker.com/_/docker.\n",
      "\n",
      "                ***** END OF NOTICE *****\n",
      "\n",
      "Sending build context to Docker daemon  368.1kB\n",
      "Step 1/2 : FROM tensorflow/tfx:0.21.4\n",
      "0.21.4: Pulling from tensorflow/tfx\n",
      "bd47987755ba: Pulling fs layer\n",
      "831c222b21d8: Pulling fs layer\n",
      "3c2cba919283: Pulling fs layer\n",
      "e378d88a5f59: Pulling fs layer\n",
      "df37508d2f5c: Pulling fs layer\n",
      "bd5056198be8: Pulling fs layer\n",
      "044a6cc327bc: Pulling fs layer\n",
      "c7411e31635f: Pulling fs layer\n",
      "29aa6e9dcc22: Pulling fs layer\n",
      "9777e791df93: Pulling fs layer\n",
      "9adf91901ea3: Pulling fs layer\n",
      "1bb0820f7158: Pulling fs layer\n",
      "8aa238cf5652: Pulling fs layer\n",
      "b57d894b9e7f: Pulling fs layer\n",
      "e378d88a5f59: Waiting\n",
      "df37508d2f5c: Waiting\n",
      "bd5056198be8: Waiting\n",
      "044a6cc327bc: Waiting\n",
      "c7411e31635f: Waiting\n",
      "29aa6e9dcc22: Waiting\n",
      "9777e791df93: Waiting\n",
      "9adf91901ea3: Waiting\n",
      "1bb0820f7158: Waiting\n",
      "8aa238cf5652: Waiting\n",
      "b57d894b9e7f: Waiting\n",
      "3c2cba919283: Download complete\n",
      "831c222b21d8: Verifying Checksum\n",
      "831c222b21d8: Download complete\n",
      "bd47987755ba: Verifying Checksum\n",
      "bd47987755ba: Download complete\n",
      "bd5056198be8: Verifying Checksum\n",
      "bd5056198be8: Download complete\n",
      "044a6cc327bc: Verifying Checksum\n",
      "044a6cc327bc: Download complete\n",
      "e378d88a5f59: Verifying Checksum\n",
      "e378d88a5f59: Download complete\n",
      "df37508d2f5c: Verifying Checksum\n",
      "df37508d2f5c: Download complete\n",
      "c7411e31635f: Verifying Checksum\n",
      "c7411e31635f: Download complete\n",
      "9777e791df93: Verifying Checksum\n",
      "9777e791df93: Download complete\n",
      "9adf91901ea3: Verifying Checksum\n",
      "9adf91901ea3: Download complete\n",
      "8aa238cf5652: Download complete\n",
      "b57d894b9e7f: Verifying Checksum\n",
      "b57d894b9e7f: Download complete\n",
      "1bb0820f7158: Verifying Checksum\n",
      "1bb0820f7158: Download complete\n",
      "29aa6e9dcc22: Download complete\n",
      "bd47987755ba: Pull complete\n",
      "831c222b21d8: Pull complete\n",
      "3c2cba919283: Pull complete\n",
      "e378d88a5f59: Pull complete\n",
      "df37508d2f5c: Pull complete\n",
      "bd5056198be8: Pull complete\n",
      "044a6cc327bc: Pull complete\n",
      "c7411e31635f: Pull complete\n",
      "29aa6e9dcc22: Pull complete\n",
      "9777e791df93: Pull complete\n",
      "9adf91901ea3: Pull complete\n",
      "1bb0820f7158: Pull complete\n",
      "8aa238cf5652: Pull complete\n",
      "b57d894b9e7f: Pull complete\n",
      "Digest: sha256:f5c313fb9dd86c3eaade35265e93d6037cc56f438924a13d32e6633e6cb3cbac\n",
      "Status: Downloaded newer image for tensorflow/tfx:0.21.4\n",
      " ---> 8acabd98b4f0\n",
      "Step 2/2 : ADD ml_pipeline ml_pipeline\n",
      " ---> ab53b2981dc9\n",
      "Successfully built ab53b2981dc9\n",
      "Successfully tagged gcr.io/ksalama-research/tfx-image:latest\n",
      "PUSH\n",
      "Pushing gcr.io/ksalama-research/tfx-image:latest\n",
      "The push refers to repository [gcr.io/ksalama-research/tfx-image]\n",
      "6dc1e0807254: Preparing\n",
      "e747e40f0d9f: Preparing\n",
      "3f33e86c4340: Preparing\n",
      "44cc94e28bfe: Preparing\n",
      "b330c0e1bd9c: Preparing\n",
      "6f0982b19304: Preparing\n",
      "f160ec1660e5: Preparing\n",
      "91ff9f0432c0: Preparing\n",
      "f977347970fc: Preparing\n",
      "2f7d29ac720e: Preparing\n",
      "84ff92691f90: Preparing\n",
      "54b00d861a7a: Preparing\n",
      "c547358928ab: Preparing\n",
      "84ff92691f90: Preparing\n",
      "c4e66be694ce: Preparing\n",
      "47cc65c6dd57: Preparing\n",
      "6f0982b19304: Waiting\n",
      "f160ec1660e5: Waiting\n",
      "91ff9f0432c0: Waiting\n",
      "f977347970fc: Waiting\n",
      "2f7d29ac720e: Waiting\n",
      "84ff92691f90: Waiting\n",
      "54b00d861a7a: Waiting\n",
      "c547358928ab: Waiting\n",
      "c4e66be694ce: Waiting\n",
      "47cc65c6dd57: Waiting\n",
      "3f33e86c4340: Layer already exists\n",
      "44cc94e28bfe: Layer already exists\n",
      "b330c0e1bd9c: Layer already exists\n",
      "e747e40f0d9f: Layer already exists\n",
      "6f0982b19304: Layer already exists\n",
      "f977347970fc: Layer already exists\n",
      "f160ec1660e5: Layer already exists\n",
      "91ff9f0432c0: Layer already exists\n",
      "84ff92691f90: Layer already exists\n",
      "c547358928ab: Layer already exists\n",
      "2f7d29ac720e: Layer already exists\n",
      "c4e66be694ce: Layer already exists\n",
      "47cc65c6dd57: Layer already exists\n",
      "54b00d861a7a: Layer already exists\n",
      "6dc1e0807254: Pushed\n",
      "latest: digest: sha256:0ee0fe6853f3edc38b358a7a2987f2d0e0e195514ef6665ab9c6eae3147bc7b0 size: 3694\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                      IMAGES                                       STATUS\n",
      "09eafa18-7649-4531-a00d-c2714802a623  2020-07-20T23:35:20+00:00  2M31S     gs://ksalama-research_cloudbuild/source/1595288119.93-9292d51ed26e482094c3c14159b00b63.tgz  gcr.io/ksalama-research/tfx-image (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag $KFP_TFX_IMAGE ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compile TFX Pipeline using CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tfx pipeline --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-20 23:38:19.685517: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-07-20 23:38:19.685668: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-07-20 23:38:19.685692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "CLI\n",
      "Compiling pipeline\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "2020-07-20 23:38:23.458438: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-07-20 23:38:23.458587: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-07-20 23:38:23.458611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/lib/python3.7/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
      "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n",
      "WARNING:absl:The \"input_data\" argument to the StatisticsGen component has been renamed to \"examples\" and is deprecated. Please update your usage as support for this argument will be removed soon.\n",
      "WARNING:absl:The \"stats\" argument to the StatisticsGen component has been renamed to \"statistics\" and is deprecated. Please update your usage as support for this argument will be removed soon.\n",
      "WARNING:absl:The \"input_data\" argument to the Transform component has been renamed to \"examples\" and is deprecated. Please update your usage as support for this argument will be removed soon.\n",
      "WARNING:absl:The \"model_export\" argument to the Pusher component has been renamed to \"model\" and is deprecated. Please update your usage as support for this argument will be removed soon.\n",
      "Pipeline compiled successfully.\n",
      "Pipeline package path: /home/tfx2-workshop/tfx_census_classification.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!tfx pipeline compile \\\n",
    "    --engine=kubeflow \\\n",
    "    --pipeline_path=ml_pipeline/runner.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy the Compiled Pipeline to KFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kfp pipeline --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Details\n",
      "------------------\n",
      "ID           dbf0ecbe-d390-424a-a867-521cc39fbcf8\n",
      "Name         tfx_census_classification\n",
      "Description\n",
      "Uploaded at  2020-07-20T23:38:35+00:00\n",
      "+--------------------+-----------------------------------------------------------------------+\n",
      "| Parameter Name     | Default Value                                                         |\n",
      "+====================+=======================================================================+\n",
      "| pipeline-root      | gs://ks-kfp-artifact-store/tfx_census_classification/{{workflow.uid}} |\n",
      "+--------------------+-----------------------------------------------------------------------+\n",
      "| eval-steps         | 500                                                                   |\n",
      "+--------------------+-----------------------------------------------------------------------+\n",
      "| train-steps        | 5000                                                                  |\n",
      "+--------------------+-----------------------------------------------------------------------+\n",
      "| accuracy-threshold | 0.75                                                                  |\n",
      "+--------------------+-----------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching cluster endpoint and auth data.\n",
      "kubeconfig entry generated for ks-ml-cluster-01.\n",
      "Pipeline dbf0ecbe-d390-424a-a867-521cc39fbcf8 has been submitted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gcloud container clusters get-credentials ${GKE_CLUSTER_NAME} --zone ${GKE_CLUSTER_ZONE}\n",
    "export KFP_ENDPOINT=$(kubectl describe configmap inverse-proxy-config -n ${NAMESPACE} | grep \"googleusercontent.com\")\n",
    "\n",
    "kfp --namespace=${NAMESPACE} --endpoint=${KFP_ENDPOINT} \\\n",
    "    pipeline upload \\\n",
    "    --pipeline-name=${PIPELINE_NAME} \\\n",
    "    ${PIPELINE_NAME}.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the KFP UI to run the deployed pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
